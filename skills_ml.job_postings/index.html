



<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-0.17.3, mkdocs-material-2.7.2">
    
    
      
        <title>Job Posting Dataset Processors - skills-ml documentation</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.8d40d89b.css">
      
    
    
      <script src="../assets/javascripts/modernizr.1aa3b519.js"></script>
    
    
      <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
      
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    
    
    
  </head>
  
    <body dir="ltr">
  
    <svg class="md-svg">
      <defs>
        
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="drawer"></label>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href=".." title="skills-ml documentation" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                skills-ml documentation
              </span>
              <span class="md-header-nav__topic">
                Job Posting Dataset Processors
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="drawer">
    <span class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </span>
    skills-ml documentation
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../examples/" title="Examples" class="md-nav__link">
      Examples
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../ontologies/" title="Ontology Class" class="md-nav__link">
      Ontology Class
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../common_schema/" title="Job Posting Common Schema" class="md-nav__link">
      Job Posting Common Schema
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../skills_ml.evaluation/" title="Evaluation Tools" class="md-nav__link">
      Evaluation Tools
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../skills_ml.algorithms/" title="Algorithms" class="md-nav__link">
      Algorithms
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="toc">
    
    
    <a href="./" title="Job Posting Dataset Processors" class="md-nav__link md-nav__link--active">
      Job Posting Dataset Processors
    </a>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../skills_ml.datasets/" title="External Dataset Processors" class="md-nav__link">
      External Dataset Processors
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="skills_ml.job_postings.aggregate">skills_ml.job_postings.aggregate</h1>

<h1 id="skills_ml.job_postings.aggregate.dataset_transform">skills_ml.job_postings.aggregate.dataset_transform</h1>

<p>Track stats of job listing datasets, before and after transformation
into the common schema.</p>
<h2 id="skills_ml.job_postings.aggregate.dataset_transform.DatasetStatsCounter">DatasetStatsCounter</h2>

<pre><code class="python">DatasetStatsCounter(self, dataset_id, quarter)
</code></pre>

<p>Accumulate data Dataset ETL statistics for a quarter
to show presence and absence of different fields,
and the total count of rows</p>
<p>Args:
    dataset_id (string) A dataset id
    quarter (string) The quarter being analyzed</p>
<h2 id="skills_ml.job_postings.aggregate.dataset_transform.DatasetStatsAggregator">DatasetStatsAggregator</h2>

<pre><code class="python">DatasetStatsAggregator(self, dataset_id, s3_conn)
</code></pre>

<p>Aggregate data Dataset ETL statistics up to the dataset level</p>
<p>Args:
    dataset_id (string) A dataset id
    s3_conn (boto.Connection) an s3 connection</p>
<h2 id="skills_ml.job_postings.aggregate.dataset_transform.GlobalStatsAggregator">GlobalStatsAggregator</h2>

<pre><code class="python">GlobalStatsAggregator(self, s3_conn)
</code></pre>

<p>Aggregate Dataset ETL statistics up to the global level</p>
<p>Args:
    s3_conn (boto.Connection) an s3 connection</p>
<h1 id="skills_ml.job_postings.aggregate.field_values">skills_ml.job_postings.aggregate.field_values</h1>

<p>Track field value distribution of common schema job postings
<h2 id="skills_ml.job_postings.aggregate.field_values.FieldValueCounter">FieldValueCounter</h2></p>
<pre><code class="python">FieldValueCounter(self, quarter, field_values)
</code></pre>

<p>Accumulate field distribution statistics for common schema job postings</p>
<p>Args:
    quarter (string) The quarter being analyzed
    field_values (list) each entry should be either:
        1. a field key
        2. a tuple, first value field key, second value function to fetch value or values from document</p>
<h1 id="skills_ml.job_postings.aggregate.pandas">skills_ml.job_postings.aggregate.pandas</h1>

<p>Aggregation functions that can be used with pandas dataframes
<h2 id="skills_ml.job_postings.aggregate.pandas.listy_n_most_common">listy_n_most_common</h2></p>
<pre><code class="python">listy_n_most_common(*params, **kwparams)
</code></pre>

<p>Expects each item to be iterable, each sub-item to be addable
<h2 id="skills_ml.job_postings.aggregate.pandas.AggregateFunction">AggregateFunction</h2></p>
<pre><code class="python">AggregateFunction(self, returns)
</code></pre>

<p>Wrap a function with an attribute that indicates the return type name
<h1 id="skills_ml.job_postings.common_schema">skills_ml.job_postings.common_schema</h1></p>
<p>A variety of common-schema job posting collections.</p>
<p>Each class in this module should implement a generator that yields job postings (in the common schema, as a JSON string), and has a 'metadata' attribute so any users of the job postings can inspect meaningful metadata about the postings.</p>
<h2 id="skills_ml.job_postings.common_schema.JobPostingCollectionFromS3">JobPostingCollectionFromS3</h2>

<pre><code class="python">JobPostingCollectionFromS3(self, s3_conn, s3_paths, extra_metadata=None)
</code></pre>

<p>Stream job posting from s3.</p>
<p>Expects that each will be stored in JSON format, one job posting per line.
The s3_path given will be iterated through as a prefix, so job postings may be
partitioned under that prefix however you choose.
It will look in every file under that prefix.</p>
<p>Example:</p>
<pre><code>import json
from airflow.hooks import S3Hook
from skills_ml.job_postings.common_schema import JobPostingGenerator
s3_conn = S3Hook().get_conn()
job_postings_generator = JobPostingCollectionFromS3(s3_conn, s3_path='my-bucket/job_postings_common_schema')
for job_posting in job_postings_generator:
    print(job_posting['title'])
</code></pre>

<p>Attributes:
    s3_conn: a boto s3 connection
    s3_path: path to the job listings. there may be multiple</p>
<h2 id="skills_ml.job_postings.common_schema.JobPostingCollectionSample">JobPostingCollectionSample</h2>

<pre><code class="python">JobPostingCollectionSample(self, num_records:int=50)
</code></pre>

<p>Stream a finite number of job postings stored within the library.</p>
<p>Example:</p>
<pre><code>import json

job_postings = JobPostingCollectionSample()
for job_posting in job_postings:
    print(json.loads(job_posting)['title'])

Meant to provide a dependency-less example of common schema job postings
for introduction to the library

Args:
    num_records (int): The maximum number of records to return. Defaults to 50 (all postings available)

&lt;h2 id=&quot;skills_ml.job_postings.common_schema.generate_job_postings_from_s3&quot;&gt;generate_job_postings_from_s3&lt;/h2&gt;

```python
generate_job_postings_from_s3(s3_conn, s3_prefix:str) -&gt; Generator[Dict[str, Any], NoneType, NoneType]
</code></pre>

<p>Stream all job listings from s3
Args:
    s3_conn: a boto s3 connection
    s3_prefix: path to the job listings.</p>
<p>Yields:
    string in json format representing the next job listing
        Refer to sample_job_listing.json for example structure</p>
<h2 id="skills_ml.job_postings.common_schema.generate_job_postings_from_s3_multiple_prefixes">generate_job_postings_from_s3_multiple_prefixes</h2>

<pre><code class="python">generate_job_postings_from_s3_multiple_prefixes(s3_conn, s3_prefixes:str) -&gt; Generator[Dict[str, Any], NoneType, NoneType]
</code></pre>

<p>Chain the generators of a list of multiple quarters
Args:
    s3_conn: a boto s3 connection
    s3_prefixes: paths to job listings</p>
<p>Return:
    a generator that all generators are chained together into</p>
<h2 id="skills_ml.job_postings.common_schema.batches_generator">batches_generator</h2>

<pre><code class="python">batches_generator(iterable, batch_size)
</code></pre>

<p>Batch generator
Args:
    iterable: an iterable
    batch_size: batch size</p>
<h1 id="skills_ml.job_postings.computed_properties">skills_ml.job_postings.computed_properties</h1>

<p>Encapsulates the computation of some piece of data for job postings, to make aggregation
and tabular datasets easy to produce
<h2 id="skills_ml.job_postings.computed_properties.JobPostingComputedProperty">JobPostingComputedProperty</h2></p>
<pre><code class="python">JobPostingComputedProperty(self, storage, partition_func=None)
</code></pre>

<p>Base class for computers of job posting properties.</p>
<p>Using this class, expensive computations can be performed once, stored on S3 per job posting
in partitions, and reused in different aggregations.</p>
<p>The base class takes care of all of the serialization and partitioning,
leaving subclasses to implement a function for computing the property of a single posting
and metadata describing the output of this function.</p>
<p>Subclasses must implement:
    - _compute_func_on_one to produce a callable that takes in a single
        job posting and returns JSON-serializable output representing the computation target.
        This function can produce objects that are kept in scope and reused,
        so properties that require a large object (e.g. a trained classifier) to do their
        computation work can be downloaded from S3 here without requiring the I/O work
        to be done over and over. (See .computers.SOCClassifyProperty for illustration)
    - property_name attribute (string) that is used when saving the computed properties
    - property_columns attribute (list) of ComputedPropertyColumns that
        map to the column names output by <code>_compute_func_on_one</code></p>
<p>Args:
    storage (skills_ml.storage.Store) A storage object in which to store the cached properties.
    partition_func (callable, optional) A function that takes a job posting and
        outputs a string that should be used as a partition key. Must be deterministic.
        Defaults to the 'datePosted' value</p>
<pre><code>    The caches will be namespaced by the property name and partition function
</code></pre>
<h2 id="skills_ml.job_postings.computed_properties.ComputedPropertyColumn">ComputedPropertyColumn</h2>

<pre><code class="python">ComputedPropertyColumn(self, name, description, compatible_aggregate_function_paths=None)
</code></pre>

<p>Metadata about a specific output column of a computed property</p>
<p>Args:
    name (string) The name of the column
    description (string) A description of the column and how it was populated.
    compatible_aggregate_function_paths (dict, optional): If this property is meant to be
        used in aggregations, map string function paths to descriptions of what the
        function is computing for this column.
        All function paths should be compatible with pandas.agg (one argument, an iterable),
        though multi-argument functions can be used in conjunction with functools.partial</p>
<h1 id="skills_ml.job_postings.computed_properties.aggregators">skills_ml.job_postings.computed_properties.aggregators</h1>

<p>Aggregate job posting computed properties into tabular datasets
<h2 id="skills_ml.job_postings.computed_properties.aggregators.df_for_properties_and_keys">df_for_properties_and_keys</h2></p>
<pre><code class="python">df_for_properties_and_keys(computed_properties, keys)
</code></pre>

<p>Assemble a dataframe with the raw data from many computed properties and keys</p>
<p>Args:
    computed_properties (list of JobPostingComputedProperty)
    keys (list of strs)</p>
<p>Returns: pandas.DataFrame</p>
<h2 id="skills_ml.job_postings.computed_properties.aggregators.expand_array_col_to_many_cols">expand_array_col_to_many_cols</h2>

<pre><code class="python">expand_array_col_to_many_cols(base_col, func, aggregation)
</code></pre>

<p>Expand an array column created as the result of an .aggregate call into many columns</p>
<p>Args:
    base_col (string) The name of the base column (before .aggregate)
    func (function) The base function that was aggregated on
    aggregation (pandas.DataFrame) The post-aggregation dataframe</p>
<p>Returns: pandas.DataFrame, minus the array column and plus columns for each array value</p>
<h2 id="skills_ml.job_postings.computed_properties.aggregators.base_func">base_func</h2>

<pre><code class="python">base_func(aggregate_function)
</code></pre>

<p>Deals with the possibility of functools.partial being applied to a given
function. Allows access to the decorated 'return' attribute whether or not
it is also a partial function</p>
<p>Args:
    aggregate_function (callable) Either a raw function or a functools.partial object</p>
<p>Returns: callable</p>
<h2 id="skills_ml.job_postings.computed_properties.aggregators.aggregation_for_properties_and_keys">aggregation_for_properties_and_keys</h2>

<pre><code class="python">aggregation_for_properties_and_keys(grouping_properties, aggregate_properties, aggregate_functions, keys)
</code></pre>

<p>Assemble an aggregation dataframe for given partition keys</p>
<p>Args:
    grouping_properties (list of JobPostingComputedProperty)
        Properties to form the primary key of the aggregation
    aggregate_properties (list of JobPostingComputedProperty)
        Properties to be aggregated over the primary key
    aggregate_functions (dict) A lookup of aggregate functions
        to be applied for each aggregate column
    keys (list of str) The desired partition keys for the aggregation to cover</p>
<p>Returns: pandas.DataFrame indexed on the grouping properties,
    covering all data from the given keys</p>
<h2 id="skills_ml.job_postings.computed_properties.aggregators.aggregate_properties">aggregate_properties</h2>

<pre><code class="python">aggregate_properties(out_filename, grouping_properties, aggregate_properties, aggregate_functions, storage, aggregation_name)
</code></pre>

<p>Aggregate computed properties and stores the resulting CSV</p>
<p>Args:
    out_filename (string) The desired filename (without path) for the .csv
    grouping_properties (list of JobPostingComputedProperty)
        Properties to form the primary key of the aggregation
    aggregate_properties (list of JobPostingComputedProperty)
        Properties to be aggregated over the primary key
    aggregate_functions (dict) A lookup of aggregate functions
        to be applied for each aggregate column
    aggregations_path (string) The base s3 path to store aggregations
    aggregation_name (string) The name of this particular aggregation</p>
<p>Returns: nothing</p>
<h1 id="skills_ml.job_postings.computed_properties.computers">skills_ml.job_postings.computed_properties.computers</h1>

<p>Various computers of job posting properties. Each class is generally a generic algorithm (such as skill extraction or occupation classification) paired with enough configuration to run on its own
<h2 id="skills_ml.job_postings.computed_properties.computers.TitleCleanPhaseOne">TitleCleanPhaseOne</h2></p>
<pre><code class="python">TitleCleanPhaseOne(self, storage, partition_func=None)
</code></pre>

<p>Perform one phase of job title cleaning: lowercase/remove punctuation
<h2 id="skills_ml.job_postings.computed_properties.computers.TitleCleanPhaseTwo">TitleCleanPhaseTwo</h2></p>
<pre><code class="python">TitleCleanPhaseTwo(self, storage, partition_func=None)
</code></pre>

<p>Perform two phases of job title cleaning:</p>
<ol>
<li>lowercase/remove punctuation</li>
<li>Remove geography information</li>
</ol>
<h2 id="skills_ml.job_postings.computed_properties.computers.CBSAandStateFromGeocode">CBSAandStateFromGeocode</h2>

<pre><code class="python">CBSAandStateFromGeocode(self, cache_storage, cache_fname, *args, **kwargs)
</code></pre>

<p>Produce a CBSA by geocoding the job's location and matching with a CBSA shapefile</p>
<p>Args:
    cache_s3_path (string) An s3 path to store geocode cache results</p>
<h2 id="skills_ml.job_postings.computed_properties.computers.SOCClassifyProperty">SOCClassifyProperty</h2>

<pre><code class="python">SOCClassifyProperty(self, classifier_obj, *args, **kwargs)
</code></pre>

<p>Classify the SOC code from a trained classifier</p>
<p>Args:
    classifier_obj (object, optional) An object to use as a classifier.
        If not sent one will be downloaded from s3</p>
<h2 id="skills_ml.job_postings.computed_properties.computers.GivenSOC">GivenSOC</h2>

<pre><code class="python">GivenSOC(self, storage, partition_func=None)
</code></pre>

<p>Assign the SOC code given by the partner
<h2 id="skills_ml.job_postings.computed_properties.computers.SkillCounts">SkillCounts</h2></p>
<pre><code class="python">SkillCounts(self, skill_extractor, *args, **kwargs)
</code></pre>

<p>Adding top skill counts from a skill extractor</p>
<p>Args: (skills_ml.algorithms.skill_extractors.base.SkillExtractorBase) A skill extractor object</p>
<h2 id="skills_ml.job_postings.computed_properties.computers.PostingIdPresent">PostingIdPresent</h2>

<pre><code class="python">PostingIdPresent(self, storage, partition_func=None)
</code></pre>

<p>Records job posting ids. Used for counting job postings
<h1 id="skills_ml.job_postings.corpora">skills_ml.job_postings.corpora</h1></p>
<p>Classes for converting collections of objects (for instance, common schema job postings) into text corpora suitable for use by natural language processing algorithms.</p>
<h1 id="skills_ml.job_postings.corpora.basic">skills_ml.job_postings.corpora.basic</h1>

<h2 id="skills_ml.job_postings.corpora.basic.CorpusCreator">CorpusCreator</h2>

<pre><code class="python">CorpusCreator(self, job_posting_generator=None, document_schema_fields=['description', 'experienceRequirements', 'qualifications', 'skills'], raw=False)
</code></pre>

<p>A base class for objects that convert common schema
job listings into a corpus in documnet level suitable for use by
machine learning algorithms or specific tasks.</p>
<p>Example:</p>
<pre><code class="python">from skills_ml.job_postings.common_schema import JobPostingCollectionSample
from skills_ml.job_postings.corpora.basic import CorpusCreator

job_postings_generator = JobPostingCollectionSample()

# Default will include all the cleaned job postings
corpus = CorpusCreator(job_postings_generator)

# For getting a the raw job postings without any cleaning
corpus = CorpusCreator(job_postings_generator, raw=True)
</code></pre>

<p>Attributes:
job_posting_generator (generator):  an iterable that generates JSON strings.
                        Each string is expected to represent a job listing
                        conforming to the common schema
                        See sample_job_listing.json for an example of this schema
document_schema_fields (list): an list of schema fields to be included
raw (bool): a flag whether to return the raw documents or transformed documents</p>
<p>Yield:
(dict): a dictinary only with selected fields as keys and corresponding raw/cleaned value</p>
<h2 id="skills_ml.job_postings.corpora.basic.SimpleCorpusCreator">SimpleCorpusCreator</h2>

<pre><code class="python">SimpleCorpusCreator(self, job_posting_generator=None, document_schema_fields=['description', 'experienceRequirements', 'qualifications', 'skills'], raw=False)
</code></pre>

<p>An object that transforms job listing documents by picking
important schema fields and returns them as one large lowercased string</p>
<h2 id="skills_ml.job_postings.corpora.basic.Doc2VecGensimCorpusCreator">Doc2VecGensimCorpusCreator</h2>

<pre><code class="python">Doc2VecGensimCorpusCreator(self, job_posting_generator, document_schema_fields=['description', 'experienceRequirements', 'qualifications', 'skills'], *args, **kwargs)
</code></pre>

<p>Corpus for training Gensim Doc2Vec
An object that transforms job listing documents by picking
important schema fields and yields them as one large cleaned array of words</p>
<p>Example:</p>
<pre><code class="python">
from skills_ml.job_postings.common_schema import JobPostingCollectionSample
from skills_ml.job_postings.corpora.basic import Doc2VecGensimCorpusCreator

job_postings_generator = JobPostingCollectionSample()

corpus = Doc2VecGensimCorpusCreator(job_postings_generator)

Attributes:
    job_posting_generator (generator): a job posting generator
    document_schema_fields (list): an list of schema fields to be included

&lt;h2 id=&quot;skills_ml.job_postings.corpora.basic.Word2VecGensimCorpusCreator&quot;&gt;Word2VecGensimCorpusCreator&lt;/h2&gt;

```python
Word2VecGensimCorpusCreator(self, job_posting_generator, document_schema_fields=['description', 'experienceRequirements', 'qualifications', 'skills'], *args, **kwargs)
</code></pre>

<p>An object that transforms job listing documents by picking
important schema fields and yields them as one large cleaned array of words</p>
<h2 id="skills_ml.job_postings.corpora.basic.JobCategoryCorpusCreator">JobCategoryCorpusCreator</h2>

<pre><code class="python">JobCategoryCorpusCreator(self, job_posting_generator=None, document_schema_fields=['description', 'experienceRequirements', 'qualifications', 'skills'], raw=False)
</code></pre>

<p>An object that extract the label of each job listing document which could be onet soc code or
occupationalCategory and yields them as a lowercased string</p>
<h2 id="skills_ml.job_postings.corpora.basic.RawCorpusCreator">RawCorpusCreator</h2>

<pre><code class="python">RawCorpusCreator(self, job_posting_generator, document_schema_fields=['description', 'experienceRequirements', 'qualifications', 'skills'])
</code></pre>

<p>An object that yields the joined raw string of job posting</p>
<h1 id="skills_ml.job_postings.filtering">skills_ml.job_postings.filtering</h1>

<p>Filtering streamed job postings
<h2 id="skills_ml.job_postings.filtering.soc_major_group_filter">soc_major_group_filter</h2></p>
<pre><code class="python">soc_major_group_filter(major_groups:List) -&gt; Callable
</code></pre>

<p>Return a function that checks the ONET Soc Code of a job posting (if it is present) against the configured major groups.</p>
<h2 id="skills_ml.job_postings.filtering.JobPostingFilterer">JobPostingFilterer</h2>

<pre><code class="python">JobPostingFilterer(self, job_posting_generator:Generator[Dict[str, Any], NoneType, NoneType], filter_funcs:List[Callable])
</code></pre>

<p>Filter common schema job postings through a number of filtering functions</p>
<p>Args:
    job_posting_generator: An iterable of job postings (each in dict form)
    filter_funcs: A list of filtering functions, each taking in a job posting document (as dict) and returning a boolean instructing whether or not the posting passes the filter</p>
<h1 id="skills_ml.job_postings.geography_queriers">skills_ml.job_postings.geography_queriers</h1>

<p>Extracting geographies from job posting datasets
<h2 id="skills_ml.job_postings.geography_queriers.job_posting_search_strings">job_posting_search_strings</h2></p>
<pre><code class="python">job_posting_search_strings(job_posting)
</code></pre>

<p>Convert a job posting to a geocode-ready search string</p>
<p>Includes city and state if present, or just city</p>
<p>Args:
    job_posting (dict) A job posting in schema.org/JobPosting json form</p>
<p>Returns: (string) A geocode-ready search string</p>
<h1 id="skills_ml.job_postings.geography_queriers.cbsa">skills_ml.job_postings.geography_queriers.cbsa</h1>

<p>Look up the CBSA for a job posting from a census crosswalk (job location -&gt; Census Place -&gt; Census UA -&gt; Census CBSA)</p>
<h2 id="skills_ml.job_postings.geography_queriers.cbsa.JobCBSAQuerier">JobCBSAQuerier</h2>

<pre><code class="python">JobCBSAQuerier(self)
</code></pre>

<p>Queries the Core-Based Statistical Area for a job using a census crosswalk</p>
<p>First looks up a Place or County Subdivision by the job posting's state and city.
If it finds a result, it will then take the Urbanized Area for that Place or County Subdivison and find CBSAs associated with it.</p>
<p>Queries return all hits, so there may be multiple CBSAs for a given query.</p>
<h1 id="skills_ml.job_postings.geography_queriers.cbsa_from_geocode">skills_ml.job_postings.geography_queriers.cbsa_from_geocode</h1>

<p>Look up the CBSA for a job posting against a precomputed geocoded CBSA lookup
<h2 id="skills_ml.job_postings.geography_queriers.cbsa_from_geocode.JobCBSAFromGeocodeQuerier">JobCBSAFromGeocodeQuerier</h2></p>
<pre><code class="python">JobCBSAFromGeocodeQuerier(self, cbsa_results)
</code></pre>

<p>Queries the Core-Based Statistical Area for a job</p>
<p>This object delegates the CBSA-finding algorithm to a passed-in cache.
In practice, you can look at the <code>skills_ml.algorithms.geocoders.cbsa</code>
module for an example of how this can be generated.</p>
<p>Instead, this object focuses on the job posting-centric logic necessary,
such as converting the job posting to the form needed to use the cache
and dealing with differents kinds of cache misses.</p>
<p>Args:
    cbsa_results (dict) A mapping of geocoding search strings to
        (CBSA FIPS, CBSA Name) tuples</p>
<h1 id="skills_ml.job_postings.raw">skills_ml.job_postings.raw</h1>

<h1 id="skills_ml.job_postings.raw.usajobs">skills_ml.job_postings.raw.usajobs</h1>

<p>Import USAJobs postings into the Open Skills common schema
<h1 id="skills_ml.job_postings.raw.virginia">skills_ml.job_postings.raw.virginia</h1></p>
<h1 id="skills_ml.job_postings.sample">skills_ml.job_postings.sample</h1>

<p>Sample job postings
<h2 id="skills_ml.job_postings.sample.JobSampler">JobSampler</h2></p>
<pre><code class="python">JobSampler(self, job_posting_generator, major_group=False, keys=None, weights=None, random_state=None)
</code></pre>

<p>Job posting sampler using reservoir sampling methods</p>
<p>It takes a job_posting generator as an input. To sample based on weights, one should sepecify a weight dictionary.</p>
<p>Attributes:
    job_posting_generator (iterator): Job posting iterator to sample from.
    major_group (bool): A flag for using major_group as a label or not
    keys (list|str): a key or keys(for nested dictionary) indicates the label which should exist in common schema
                     of job posting.
    weights (dict): a dictionary that has key-value pairs as label-weighting pairs. It expects every
                    label in the iterator to be present as a key in the weights dictionary For example,
                    weights = {'11': 2, '13', 1}. In this case, the label/key is the occupation major
                    group and the value is the weight you want to sample with.
    random_state (int): the seed used by the random number generator</p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../skills_ml.algorithms/" title="Algorithms" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Algorithms
              </span>
            </div>
          </a>
        
        
          <a href="../skills_ml.datasets/" title="External Dataset Processors" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                External Dataset Processors
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="http://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.b438e6c5.js"></script>
      
      <script>app.initialize({version:"0.17.3",url:{base:".."}})</script>
      
    
    
      
    
  </body>
</html>